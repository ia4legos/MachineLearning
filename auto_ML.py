# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ouWdD_hfb8hSlpNdJSdN2vI-KHk5Uwye
"""

import warnings
# Ignorar advertencias de convergencia para los modelos lineales
warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')

# Preprocesado
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
# División muestras
from sklearn.model_selection import train_test_split

# Modelos de clasificación
from sklearn.linear_model import LogisticRegression, RidgeClassifier, LinearRegression, Lasso, Ridge
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn.svm import SVC, SVR
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier
from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor
from lightgbm import LGBMClassifier, LGBMRegressor
from xgboost import XGBClassifier, XGBRegressor

# métricas de clasificación
from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, recall_score
from sklearn.metrics import roc_auc_score, roc_curve, classification_report, confusion_matrix, ConfusionMatrixDisplay

# métricas de regresión
from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error

# Función para el preprocesado de dataframe
def preprocesar_datos(df, target):
    """
    Preprocesa un DataFrame aplicando imputación y escalado a variables numéricas,
    e imputación y codificación One-Hot a variables categóricas/booleanas.

    Args:
        df (pd.DataFrame): El DataFrame a preprocesar.
        target (str): El nombre de la columna objetivo.

    Returns:
        pd.DataFrame: El DataFrame preprocesado.
    """

    # quitamos el target para el preprocesado
    dfs = df.drop(target, axis=1)

    # Identificar tipos de variables
    numeric_features = dfs.select_dtypes(include=np.number).columns
    categorical_features = dfs.select_dtypes(include=['object', 'category', 'bool']).columns
    # Número de cada tipo de variables
    lnum = len(numeric_features)
    lcat = len(categorical_features)

    # Crear pipelines para el preprocesado numérico y categórico en función del número de varaibles
    # de tipo numérico o categórico

    ### Variables de ambos tipos
    if (lnum > 0) & (lcat >0):
          # Pipeline para variables numéricas: imputación con mediana y estandarización
          numeric_transformer = Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='median')),
            ('scaler', StandardScaler())
          ])
          # Pipeline para variables categóricas: imputación con moda y codificación One-Hot
          categorical_transformer = Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='most_frequent')),
            ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first')) # drop='first' elimina la primera categoría
           ])
          # Combinar los preprocesamientos utilizando ColumnTransformer
          preprocessor = ColumnTransformer(
            transformers=[
              ('num', numeric_transformer, numeric_features),
              ('cat', categorical_transformer, categorical_features)
           ])
          # Aplicar el preprocesado al DataFrame
          df_preprocessed = preprocessor.fit_transform(dfs)
          # Asignación de nombres de variables
          cat_feature_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features)
          all_feature_names = list(numeric_features) + list(cat_feature_names)
          df_preprocessed = pd.DataFrame(df_preprocessed, columns=all_feature_names, index=df.index)

    ### Variables de tipo numérico sin variables de tipo categórico
    if (lnum > 0) & (lcat == 0):
          # Pipeline para variables numéricas: imputación con mediana y estandarización
          numeric_transformer = Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='median')),
            ('scaler', StandardScaler())
          ])
           # Combinar los preprocesamientos utilizando ColumnTransformer
          preprocessor = ColumnTransformer(
            transformers=[
              ('num', numeric_transformer, numeric_features)
           ])
          # Aplicar el preprocesado al DataFrame
          df_preprocessed = preprocessor.fit_transform(dfs)
          # Asignación de nombres de variables
          all_feature_names = list(numeric_features)
          df_preprocessed = pd.DataFrame(df_preprocessed, columns=all_feature_names, index=df.index)

    ### Variables de categórico sin varaibles de tipo numérico
    if (lnum == 0) & (lcat >0):
          # Pipeline para variables categóricas: imputación con moda y codificación One-Hot
          categorical_transformer = Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='most_frequent')),
            ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first')) # drop='first' elimina la primera categoría
           ])
          # Combinar los preprocesamientos utilizando ColumnTransformer
          preprocessor = ColumnTransformer(
            transformers=[
              ('cat', categorical_transformer, categorical_features)
           ])
          # Aplicar el preprocesado al DataFrame
          df_preprocessed = preprocessor.fit_transform(dfs)
          # Asignación de nombres de variables
          cat_feature_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features)
          all_feature_names = list(cat_feature_names)
          df_preprocessed = pd.DataFrame(df_preprocessed, columns=all_feature_names, index=df.index)

    datos = pd.concat([df_preprocessed, df[target]], axis=1)

    return datos

# Función para muestreo estratificado por target

def split_sample(df, target, size, semilla):
  """
  Función para obtener la división de muestras de entrenamiento y test estratificando por un factor.

  Parámetros de entrada:
  - df: dataframe de datos completo
  - target: target por el que estratificar
  - size: porcentaje de la muestra de test
  - semilla: semilla aleatoria para la división y reproducibilidad
  """

  X = df.drop(target,axis=1)
  y = df[target]

  # Verificar si el target es categórico (object o category)
  if df[target].dtype == 'object' or df[target].dtype.name == 'category' or df[target].dtype.name == 'bolean':
      print(f"Estratificando por la variable objetivo '{target}' (categórica).")
      # División de muestras con estratificación
      X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=size, random_state=semilla, stratify=y)
  else:
      print(f"No estratificando por la variable objetivo '{target}' (no categórica).")
      # División de muestras sin estratificación
      X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=size, random_state=semilla)

  # Dataframes de entrenamiento y test
  strain = pd.concat([X_train,y_train],axis=1).reset_index(drop=True)
  stest = pd.concat([X_test,y_test],axis=1).reset_index(drop=True)

  return(strain,stest)

# Función para comparar diferentes modelos de clasificación binaria

def comparar_clasificador_2cls(X_train, y_train, models_to_train = None):
    """
    Entrena varios modelos de clasificación y devuelve sus métricas de rendimiento.

    Args:
        X_train (pd.DataFrame): Matriz de características de entrenamiento.
        y_train (pd.Series): Vector de target de entrenamiento.
        models_to_train (list, optional): Lista de nombres de modelos a entrenar.
                                          Si es None, entrena todos los modelos definidos.

    Returns:
        pd.DataFrame: DataFrame con las métricas (accuracy, balanced accuracy, Recall, F1, auc) para cada modelo.
    """

    # Definir los modelos a entrenar (conjunto completo)
    all_classifiers = {
        "lr": LogisticRegression(random_state=123,solver="saga"),
        "ridge": RidgeClassifier(random_state=123),
        "lda": LinearDiscriminantAnalysis(),
        "qda": QuadraticDiscriminantAnalysis(),
        "nb": GaussianNB(),
        "knn": KNeighborsClassifier(),
        "svc": SVC(kernel='linear', random_state=123),
        "rbf": SVC(kernel='rbf', random_state=123),
        "dt": DecisionTreeClassifier(random_state=123),
        "rf": RandomForestClassifier(random_state=123),
        "ada": AdaBoostClassifier(random_state=123),
        "gbc": GradientBoostingClassifier(random_state=123),
        "lightgbm": LGBMClassifier(random_state=123, verbose=-1), #verbose=-1 para evitar imprimir info de entrenamiento
        "xgboost": XGBClassifier(random_state=123, eval_metric='logloss') # use_label_encoder=False y eval_metric para evitar warnings
    }

    # Seleccionar los modelos a entrenar según la lista proporcionada
    if models_to_train is None:
        classifiers = all_classifiers
    else:
        classifiers = {name: all_classifiers[name] for name in models_to_train if name in all_classifiers}
        if len(classifiers) != len(models_to_train):
            print("Advertencia: Algunos nombres de modelos en la lista proporcionada no son válidos.")

    # Entrenamiento y almacenamienyo de métricas
    results = []
    for name, clf in classifiers.items():
        print(f"Entrenando {name}...")
        try:
            # Entrenar el modelo
            clf.fit(X_train, y_train)
            # Predecir en los datos de entrenamiento para calcular las métricas
            y_pred = clf.predict(X_train)
            # Calcular métricas
            acc = accuracy_score(y_train, y_pred)
            balanced_acc = balanced_accuracy_score(y_train, y_pred)
            # Usar average='weighted' para métricas en problemas multiclase
            precision = precision_score(y_train, y_pred, average='weighted', zero_division=0)
            recall = recall_score(y_train, y_pred, average='weighted', zero_division=0)
            f1 = f1_score(y_train, y_pred, average='weighted', zero_division=0)
            auc = roc_auc_score(y_train, y_pred)
            results.append({'Algorithm': name, 'Accuracy': acc, 'Balanced_Accuracy': balanced_acc, 'Precision': precision, 'Recall': recall, 'F1': f1, 'AUC': auc})

        except Exception as e:
            print(f"Error entrenando {name}: {e}")
            results.append({'Algorithm': name, 'Accuracy': None, 'Balanced_Accuracy': None, 'Precision': None, 'Recall': None, 'F1-score': None,})


    return pd.DataFrame(results)

# Función para comparar diferentes modelos de clasificación multinomial

def comparar_clasificador_multicls(X_train, y_train, models_to_train = None):
    """
    Entrena varios modelos de clasificación multiclase y devuelve sus métricas de rendimiento.

    Args:
        X_train (pd.DataFrame): Matriz de características de entrenamiento.
        y_train (pd.Series): Vector de target de entrenamiento (etiquetas numéricas).
        models_to_train (list, optional): Lista de nombres de modelos a entrenar.
                                          Si es None, entrena todos los modelos definidos.

    Returns:
        pd.DataFrame: DataFrame con las métricas (Accuracy, Balanced Accuracy, Precision, Recall, F1) para cada modelo.
    """

    # Definir los modelos a entrenar (conjunto completo)

    all_classifiers = {
        "lr": LogisticRegression(random_state=123, solver='liblinear'), # Usar solver compatible con multiclase
        "ridge": RidgeClassifier(random_state=123),
        "lda": LinearDiscriminantAnalysis(),
        "qda": QuadraticDiscriminantAnalysis(),
        "nb": GaussianNB(),
        "knn": KNeighborsClassifier(),
        "svc": SVC(kernel='linear', random_state=123),
        "rbf": SVC(kernel='rbf', random_state=123),
        "dt": DecisionTreeClassifier(random_state=123),
        "rf": RandomForestClassifier(random_state=123),
        "ada": AdaBoostClassifier(random_state=123),
        "gbc": GradientBoostingClassifier(random_state=123),
        "lightgbm": LGBMClassifier(random_state=123, verbose=-1),
        "xgboost": XGBClassifier(random_state=123, eval_metric='logloss')
    }

    # Seleccionar los modelos a entrenar según la lista proporcionada
    if models_to_train is None:
        classifiers = all_classifiers
    else:
        classifiers = {name: all_classifiers[name] for name in models_to_train if name in all_classifiers}
        if len(classifiers) != len(models_to_train):
            print("Advertencia: Algunos nombres de modelos en la lista proporcionada no son válidos.")

    results = []

    for name, clf in classifiers.items():
        print(f"Entrenando {name}...")
        try:
            # Entrenar el modelo
            clf.fit(X_train, y_train)

            # Predecir en los datos de entrenamiento para calcular las métricas
            y_pred = clf.predict(X_train)

            # Calcular métricas
            acc = accuracy_score(y_train, y_pred)
            balanced_acc = balanced_accuracy_score(y_train, y_pred)
            # Usar average='weighted' para métricas en problemas multiclase
            precision = precision_score(y_train, y_pred, average='weighted', zero_division=0)
            recall = recall_score(y_train, y_pred, average='weighted', zero_division=0)
            f1 = f1_score(y_train, y_pred, average='weighted', zero_division=0)

            results.append({'Algorithm': name, 'Accuracy': acc, 'Balanced_Accuracy': balanced_acc, 'Precision': precision, 'Recall': recall, 'F1-score': f1})

        except Exception as e:
            print(f"Error entrenando {name}: {e}")
            results.append({'Algorithm': name, 'Accuracy': None, 'Balanced_Accuracy': None, 'Precision': None, 'Recall': None, 'F1-score': None,})


    return pd.DataFrame(results)

# Función para comparar diferentes modelos de regresión

def comparar_regresores(X_train, y_train, models_to_train=None):
    """
    Entrena varios modelos de regresión y devuelve sus métricas de rendimiento.

    Args:
        X_train (pd.DataFrame): Matriz de características de entrenamiento.
        y_train (pd.Series): Vector de target de entrenamiento.
        models_to_train (list, optional): Lista de nombres de modelos a entrenar.
                                          Si es None, entrena todos los modelos definidos.

    Returns:
        pd.DataFrame: DataFrame con las métricas (MSE, RMSE, MAE, MAPE) para cada modelo.
    """

    # Definir los modelos a entrenar (conjunto completo)
    all_regressors = {
        "lr": LinearRegression(),
        "lasso": Lasso(random_state=123),
        "ridge": Ridge(random_state=123),
        "knn": KNeighborsRegressor(),
        "svr": SVR(),
        "dt": DecisionTreeRegressor(random_state=123),
        "rf": RandomForestRegressor(random_state=123),
        "ada": AdaBoostRegressor(random_state=123),
        "gbr": GradientBoostingRegressor(random_state=123),
        "lightgbm": LGBMRegressor(random_state=123, verbose=-1), #verbose=-1 para evitar imprimir info de entrenamiento
        "xgboost": XGBRegressor(random_state=123, use_label_encoder=False, eval_metric='rmse') # use_label_encoder=False y eval_metric para evitar warnings
    }

    # Seleccionar los modelos a entrenar según la lista proporcionada
    if models_to_train is None:
        regressors = all_regressors
    else:
        regressors = {name: all_regressors[name] for name in models_to_train if name in all_regressors}
        if len(regressors) != len(models_to_train):
            print("Advertencia: Algunos nombres de modelos en la lista proporcionada no son válidos.")

    results = []

    for name, reg in regressors.items():
        print(f"Entrenando {name}...")
        try:
            # Entrenar el modelo
            reg.fit(X_train, y_train)

            # Predecir en los datos de entrenamiento para calcular las métricas
            y_pred = reg.predict(X_train)

            # Calcular métricas
            mse = mean_squared_error(y_train, y_pred)
            rmse = np.sqrt(mse)
            mae = mean_absolute_error(y_train, y_pred)
            # Manejar el caso de división por cero en MAPE si hay valores de y_train igual a cero
            mape = mean_absolute_percentage_error(y_train, y_pred) if not (y_train == 0).any() else np.nan

            results.append({'Algorithm': name, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape})

        except Exception as e:
            print(f"Error entrenando {name}: {e}")
            results.append({'Algorithm': name, 'MSE': None, 'RMSE': None, 'MAE': None, 'MAPE': None})

    return pd.DataFrame(results)
