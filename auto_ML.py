# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ouWdD_hfb8hSlpNdJSdN2vI-KHk5Uwye
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np          # importamos numpy como np
import pandas as pd         # importamos pandas como pd
import math
import random
import warnings
# Ignorar advertencias de convergencia para los modelos lineales
warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')

# Cargamos módulos de análisis gráficos
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
sns.set_theme(style = 'whitegrid')
# %config InlineBackend.figure_format = 'retina'

# Preprocesado
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
# División muestras
from sklearn.model_selection import train_test_split

# Modelos de clasificación
from sklearn.linear_model import LogisticRegression, RidgeClassifier, LinearRegression, Lasso, Ridge
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn.svm import SVC, SVR
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier
from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor
from lightgbm import LGBMClassifier, LGBMRegressor
from xgboost import XGBClassifier, XGBRegressor

# métricas de clasificación
from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, recall_score
from sklearn.metrics import roc_auc_score, roc_curve, classification_report, confusion_matrix, ConfusionMatrixDisplay

# métricas de regresión
from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error

# Función para el preprocesado de dataframe
def preprocesar_datos(df, target):
    """
    Preprocesa un DataFrame aplicando imputación y escalado a variables numéricas,
    e imputación y codificación One-Hot a variables categóricas/booleanas.

    Args:
        df (pd.DataFrame): El DataFrame a preprocesar.
        target (str): El nombre de la columna objetivo. Si es None preprocesamos sin target

    Returns:
        pd.DataFrame: El DataFrame preprocesado.
    """

    # Seleccionamos datos de trabajo si tenemos o no el target
    if target == "None":
      dfs = df.copy()
    else:
      dfs = df.drop(target, axis=1)

    # Identificar tipos de variables
    numeric_features = dfs.select_dtypes(include=np.number).columns
    categorical_features = dfs.select_dtypes(include=['object', 'category', 'bool']).columns
    # Número de cada tipo de variables
    lnum = len(numeric_features)
    lcat = len(categorical_features)

    # Crear pipelines para el preprocesado numérico y categórico en función del número de varaibles
    # de tipo numérico o categórico

    ### Variables de ambos tipos
    if (lnum > 0) & (lcat >0):
          # Pipeline para variables numéricas: imputación con mediana y estandarización
          numeric_transformer = Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='median')),
            ('scaler', StandardScaler())
          ])
          # Pipeline para variables categóricas: imputación con moda y codificación One-Hot
          categorical_transformer = Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='most_frequent')),
            ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first')) # drop='first' elimina la primera categoría
           ])
          # Combinar los preprocesamientos utilizando ColumnTransformer
          preprocessor = ColumnTransformer(
            transformers=[
              ('num', numeric_transformer, numeric_features),
              ('cat', categorical_transformer, categorical_features)
           ])
          # Aplicar el preprocesado al DataFrame
          df_preprocessed = preprocessor.fit_transform(dfs)
          # Asignación de nombres de variables
          cat_feature_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features)
          all_feature_names = list(numeric_features) + list(cat_feature_names)
          df_preprocessed = pd.DataFrame(df_preprocessed, columns=all_feature_names, index=df.index)

    ### Variables de tipo numérico sin variables de tipo categórico
    if (lnum > 0) & (lcat == 0):
          # Pipeline para variables numéricas: imputación con mediana y estandarización
          numeric_transformer = Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='median')),
            ('scaler', StandardScaler())
          ])
           # Combinar los preprocesamientos utilizando ColumnTransformer
          preprocessor = ColumnTransformer(
            transformers=[
              ('num', numeric_transformer, numeric_features)
           ])
          # Aplicar el preprocesado al DataFrame
          df_preprocessed = preprocessor.fit_transform(dfs)
          # Asignación de nombres de variables
          all_feature_names = list(numeric_features)
          df_preprocessed = pd.DataFrame(df_preprocessed, columns=all_feature_names, index=df.index)

    ### Variables de categórico sin varaibles de tipo numérico
    if (lnum == 0) & (lcat >0):
          # Pipeline para variables categóricas: imputación con moda y codificación One-Hot
          categorical_transformer = Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='most_frequent')),
            ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first')) # drop='first' elimina la primera categoría
           ])
          # Combinar los preprocesamientos utilizando ColumnTransformer
          preprocessor = ColumnTransformer(
            transformers=[
              ('cat', categorical_transformer, categorical_features)
           ])
          # Aplicar el preprocesado al DataFrame
          df_preprocessed = preprocessor.fit_transform(dfs)
          # Asignación de nombres de variables
          cat_feature_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features)
          all_feature_names = list(cat_feature_names)
          df_preprocessed = pd.DataFrame(df_preprocessed, columns=all_feature_names, index=df.index)

    if target == "None":
      datos = df_preprocessed.copy()
    else:
      datos = pd.concat([df_preprocessed, df[target]], axis=1)

    return datos

# Función para muestreo estratificado por target

def split_sample(df, target, size, semilla):
  """
  Función para obtener la división de muestras de entrenamiento y test estratificando por un factor.

  Parámetros de entrada:
  - df: dataframe de datos completo
  - target: target por el que estratificar
  - size: porcentaje de la muestra de test
  - semilla: semilla aleatoria para la división y reproducibilidad
  """

  X = df.drop(target,axis=1)
  y = df[target]

  # Verificar si el target es categórico (object o category)
  if df[target].dtype == 'object' or df[target].dtype.name == 'category' or df[target].dtype.name == 'bolean':
      print(f"Estratificando por la variable objetivo '{target}' (categórica).")
      # División de muestras con estratificación
      X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=size, random_state=semilla, stratify=y)
  else:
      print(f"No estratificando por la variable objetivo '{target}' (no categórica).")
      # División de muestras sin estratificación
      X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=size, random_state=semilla)

  # Dataframes de entrenamiento y test
  strain = pd.concat([X_train,y_train],axis=1).reset_index(drop=True)
  stest = pd.concat([X_test,y_test],axis=1).reset_index(drop=True)

  return(strain,stest)

# Función para comparar diferentes modelos de clasificación binaria

def comparar_clasificador_2cls(X_train, y_train, models_to_train = None):
    """
    Entrena varios modelos de clasificación y devuelve sus métricas de rendimiento.

    Args:
        X_train (pd.DataFrame): Matriz de características de entrenamiento.
        y_train (pd.Series): Vector de target de entrenamiento.
        models_to_train (list, optional): Lista de nombres de modelos a entrenar.
                                          Si es None, entrena todos los modelos definidos.

    Returns:
        pd.DataFrame: DataFrame con las métricas (Precision, Recall, F1) para cada modelo.
    """

    # Definir los modelos a entrenar (conjunto completo)
    all_classifiers = {
        "lr": LogisticRegression(random_state=123,solver="saga"),
        "ridge": RidgeClassifier(random_state=123),
        "lda": LinearDiscriminantAnalysis(),
        "qda": QuadraticDiscriminantAnalysis(),
        "nb": GaussianNB(),
        "knn": KNeighborsClassifier(),
        "svc": SVC(kernel='linear', random_state=123),
        "rbf": SVC(kernel='rbf', random_state=123),
        "dt": DecisionTreeClassifier(random_state=123),
        "rf": RandomForestClassifier(random_state=123),
        "ada": AdaBoostClassifier(random_state=123),
        "gbc": GradientBoostingClassifier(random_state=123),
        "lightgbm": LGBMClassifier(random_state=123, verbose=-1), #verbose=-1 para evitar imprimir info de entrenamiento
        "xgboost": XGBClassifier(random_state=123, eval_metric='logloss') # use_label_encoder=False y eval_metric para evitar warnings
    }

    # Seleccionar los modelos a entrenar según la lista proporcionada
    if models_to_train is None:
        classifiers = all_classifiers
    else:
        classifiers = {name: all_classifiers[name] for name in models_to_train if name in all_classifiers}
        if len(classifiers) != len(models_to_train):
            print("Advertencia: Algunos nombres de modelos en la lista proporcionada no son válidos.")

    # Entrenamiento y almacenamienyo de métricas
    results = []
    for name, clf in classifiers.items():
        print(f"Entrenando {name}...")
        try:
            # Entrenar el modelo
            clf.fit(X_train, y_train)
            # Predecir en los datos de entrenamiento para calcular las métricas
            y_pred = clf.predict(X_train)
            # Calcular métricas
            acc = accuracy_score(y_train, y_pred)
            balanced_acc = balanced_accuracy_score(y_train, y_pred)
            # Usar average='weighted' para métricas en problemas multiclase
            precision = precision_score(y_train, y_pred, average='weighted', zero_division=0)
            recall = recall_score(y_train, y_pred, average='weighted', zero_division=0)
            f1 = f1_score(y_train, y_pred, average='weighted', zero_division=0)
            auc = roc_auc_score(y_train, y_pred)
            results.append({'Algorithm': name, 'Accuracy': acc, 'Balanced_Accuracy': balanced_acc, 'Precision': precision, 'Recall': recall, 'F1': f1, 'AUC': auc})

        except Exception as e:
            print(f"Error entrenando {name}: {e}")
            results.append({'Algorithm': name, 'Accuracy': None, 'Balanced_Accuracy': None, 'Precision': None, 'Recall': None, 'F1-score': None,})


    return pd.DataFrame(results)

# Función para comparar diferentes modelos de clasificación multinomial

def comparar_clasificador_multicls(X_train, y_train, models_to_train = None):
    """
    Entrena varios modelos de clasificación multiclase y devuelve sus métricas de rendimiento.

    Args:
        X_train (pd.DataFrame): Matriz de características de entrenamiento.
        y_train (pd.Series): Vector de target de entrenamiento (etiquetas numéricas).
        models_to_train (list, optional): Lista de nombres de modelos a entrenar.
                                          Si es None, entrena todos los modelos definidos.

    Returns:
        pd.DataFrame: DataFrame con las métricas (Accuracy, Balanced Accuracy, Precision, Recall, F1) para cada modelo.
    """

    # Definir los modelos a entrenar (conjunto completo)

    all_classifiers = {
        "lr": LogisticRegression(random_state=123, solver='liblinear'), # Usar solver compatible con multiclase
        "ridge": RidgeClassifier(random_state=123),
        "lda": LinearDiscriminantAnalysis(),
        "qda": QuadraticDiscriminantAnalysis(),
        "nb": GaussianNB(),
        "knn": KNeighborsClassifier(),
        "svc": SVC(kernel='linear', random_state=123),
        "rbf": SVC(kernel='rbf', random_state=123),
        "dt": DecisionTreeClassifier(random_state=123),
        "rf": RandomForestClassifier(random_state=123),
        "ada": AdaBoostClassifier(random_state=123),
        "gbc": GradientBoostingClassifier(random_state=123),
        "lightgbm": LGBMClassifier(random_state=123, verbose=-1),
        "xgboost": XGBClassifier(random_state=123, eval_metric='logloss')
    }

    # Seleccionar los modelos a entrenar según la lista proporcionada
    if models_to_train is None:
        classifiers = all_classifiers
    else:
        classifiers = {name: all_classifiers[name] for name in models_to_train if name in all_classifiers}
        if len(classifiers) != len(models_to_train):
            print("Advertencia: Algunos nombres de modelos en la lista proporcionada no son válidos.")

    results = []

    for name, clf in classifiers.items():
        print(f"Entrenando {name}...")
        try:
            # Entrenar el modelo
            clf.fit(X_train, y_train)

            # Predecir en los datos de entrenamiento para calcular las métricas
            y_pred = clf.predict(X_train)

            # Calcular métricas
            acc = accuracy_score(y_train, y_pred)
            balanced_acc = balanced_accuracy_score(y_train, y_pred)
            # Usar average='weighted' para métricas en problemas multiclase
            precision = precision_score(y_train, y_pred, average='weighted', zero_division=0)
            recall = recall_score(y_train, y_pred, average='weighted', zero_division=0)
            f1 = f1_score(y_train, y_pred, average='weighted', zero_division=0)

            results.append({'Algorithm': name, 'Accuracy': acc, 'Balanced_Accuracy': balanced_acc, 'Precision': precision, 'Recall': recall, 'F1-score': f1})

        except Exception as e:
            print(f"Error entrenando {name}: {e}")
            results.append({'Algorithm': name, 'Accuracy': None, 'Balanced_Accuracy': None, 'Precision': None, 'Recall': None, 'F1-score': None,})


    return pd.DataFrame(results)

# Función para comparar diferentes modelos de regresión

def comparar_regresores(X_train, y_train, models_to_train=None):
    """
    Entrena varios modelos de regresión y devuelve sus métricas de rendimiento.

    Args:
        X_train (pd.DataFrame): Matriz de características de entrenamiento.
        y_train (pd.Series): Vector de target de entrenamiento.
        models_to_train (list, optional): Lista de nombres de modelos a entrenar.
                                          Si es None, entrena todos los modelos definidos.

    Returns:
        pd.DataFrame: DataFrame con las métricas (MSE, RMSE, MAE, MAPE) para cada modelo.
    """

    # Definir los modelos a entrenar (conjunto completo)
    all_regressors = {
        "lr": LinearRegression(),
        "lasso": Lasso(random_state=123),
        "ridge": Ridge(random_state=123),
        "knn": KNeighborsRegressor(),
        "svr": SVR(),
        "dt": DecisionTreeRegressor(random_state=123),
        "rf": RandomForestRegressor(random_state=123),
        "ada": AdaBoostRegressor(random_state=123),
        "gbr": GradientBoostingRegressor(random_state=123),
        "lightgbm": LGBMRegressor(random_state=123, verbose=-1), #verbose=-1 para evitar imprimir info de entrenamiento
        "xgboost": XGBRegressor(random_state=123, use_label_encoder=False, eval_metric='rmse') # use_label_encoder=False y eval_metric para evitar warnings
    }

    # Seleccionar los modelos a entrenar según la lista proporcionada
    if models_to_train is None:
        regressors = all_regressors
    else:
        regressors = {name: all_regressors[name] for name in models_to_train if name in all_regressors}
        if len(regressors) != len(models_to_train):
            print("Advertencia: Algunos nombres de modelos en la lista proporcionada no son válidos.")

    results = []

    for name, reg in regressors.items():
        print(f"Entrenando {name}...")
        try:
            # Entrenar el modelo
            reg.fit(X_train, y_train)

            # Predecir en los datos de entrenamiento para calcular las métricas
            y_pred = reg.predict(X_train)

            # Calcular métricas
            mse = mean_squared_error(y_train, y_pred)
            rmse = np.sqrt(mse)
            mae = mean_absolute_error(y_train, y_pred)
            # Manejar el caso de división por cero en MAPE si hay valores de y_train igual a cero
            mape = mean_absolute_percentage_error(y_train, y_pred) if not (y_train == 0).any() else np.nan

            results.append({'Algorithm': name, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape})

        except Exception as e:
            print(f"Error entrenando {name}: {e}")
            results.append({'Algorithm': name, 'MSE': None, 'RMSE': None, 'MAE': None, 'MAPE': None})

    return pd.DataFrame(results)

def reports_clas(modelo, xtrain, ytrain, xtest, ytest):
  '''
  Función para obtener el report de clasificación para un modelo de clasifcación. Porpociona los resultados para la muestra de entrenamiento y test

  Argumentos:
  - modelo: modelo entrenado
  - xtrain: inputs de entrenamiento
  - ytrain: target de entrenamiento
  - xtest: inputs de test
  - ytest: target de test

  Return
   - reporte de clasificación para muestra de entrenamiento y test
  '''
  from sklearn.metrics import classification_report

  clase_train = modelo.predict(xtrain)
  clase_test = modelo.predict(xtest)
  print("Métricas de clasificación en la muestra de entrenamiento")
  print(classification_report(ytrain, clase_train))
  print("\n Métricas de clasificación en la muestra test")
  print(classification_report(ytest, clase_test))

def matriz_confusion(modelo, xtest, ytest):
  '''
  Función que proporciona la matriz de confusión de un modelo de clasificación en términos de los porcentajes de clasificación correcta dentro de cada clase

  Argumentos de entrada:
  - modelo: modelo entrenado
  - xtest: inputs de test
  - ytest: target de test

  Return:
  - Matriz de confusión
  '''
  from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

  pred_test = modelo.predict(xtest)
  # Matriz de confusión para datos de test
  cm = confusion_matrix(ytest, pred_test, labels = modelo.classes_)
  # Normalizamos para representar porcentajes en lugar de frecuencias
  cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
  # Solución gráfica
  disp = ConfusionMatrixDisplay(confusion_matrix = cm_normalized, display_labels = modelo.classes_)
  disp = disp.plot(cmap = plt.cm.Blues, values_format ='.2%')
  plt.grid(False)
  plt.show()

def validar_modelo(modelo, strain, stest, score, folds):
  '''
  Función que proporciona un análisis de validación cruzada con respecto a un score de evaluación

  Argumentos de entrada:
  - modelo: modelo entrenado
  - xtrain: inputs de entrenamiento
  - ytrain: target de entrenamiento
  - score: métrica de evaluación ('accuracy','recall','f1')
  - folds: número de folds de validación cruzada

  Return:
  - tabla con el análisis de validación cruzada
  '''

  from sklearn.model_selection import cross_val_score, learning_curve

  # Análsiis de validación cruzada
  score_val = pd.DataFrame(cross_val_score(modelo, xtrain, ytrain, cv = folds,
                                         scoring = score),
                                         columns=['score'])
  print("Análisis de validación cruzada")
  print(score_val.describe().T)

def curva_aprendizaje(modelo, X, y, score, folds):
  '''
  Función que proporciona un análisis de validación cruzada con respecto a un score de evaluación

  Argumentos de entrada:
  - modelo: modelo entrenado
  - X: inputs
  - y: target
  - score: métrica de evaluación ('accuracy','recall','f1')
  - folds: número de folds de validación cruzada

  Return:
  - tabla con el análisis de validación cruzada
  '''
  from sklearn.model_selection import cross_val_score, learning_curve

  #Fijamos tamaños de muestra de entrenamiento
  size = np.arange(0.2, 0.91, 0.1)
  # Evaluamos la exactitud en la muestra test para los diferentes tamaños
  train_sizes, train_scores, test_scores = learning_curve(modelo, X, y,
                                                        train_sizes = size,
                                                        scoring = score,
                                                        cv = folds)
  # Representamos gráficamente
  plt.plot(size, test_scores.mean(1), "o--", color="r")
  plt.xlabel("Proporción muestra entrenamiento")
  plt.ylabel("Promedio score")
  plt.title("Curva de aprendizaje")
  plt.grid(True)
  plt.show()